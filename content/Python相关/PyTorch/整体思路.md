数据清洗
定义数据集对象Datasets
将数据集对象转化为数据加载器对象Data Loader

定义模型Model、Net
定义损失函数L(Net, y)
定有优化算法，得到优化器optimizer，如SGD

参数初始化

循环训练模型：
 梯度初始化
 L.backward()
 迭代优化参数optimizer.step() 

得到最终模型


##  基本配置
GPU
我们前面介绍了GPU的概念和GPU用于并行计算加速的功能，不过**程序默认是在CPU上运行的**，因此在代码实现中，需要把模型和数据“放到”GPU上去做运算，同时还需要保证损失函数和优化器能够在GPU上工作。如果使用多张GPU进行训练，还需要考虑模型和数据分配、整合的问题。此外，后续计算一些指标还需要把数据“放回”CPU。这里涉及到了一系列**有关于GPU的配置和操作**。

**深度学习中训练和验证过程最大的特点在于读入数据是按批的，每次读入一个批次的数据，放入GPU中训练，然后将损失函数反向传播回网络最前面的层，同时使用优化器调整网络参数。这里会涉及到各个模块配合的问题。训练/验证后还需要根据设定好的指标计算模型表现。**

[[t.to()]]

## **数据的预处理**
其中重要的步骤包括数据格式的统一、异常数据的消除和必要的数据变换，

## **划分训练集、验证集、测试集**
常见的方法包括：按比例随机选取，KFold方法（我们可以使用sklearn带的test_train_split函数、kfold来实现）。

数据的读入
[[data.Dataset]]通过**自定义的方式**
或这直接使用现成的Dataset数据集！

数据加载
[[data.DataLoader()]]创建**数据加载器**，以便加载Dataset数据集对象，从而实现小批次加载获得更小单位的数据集
[[iter()]] 将对象转换为可**迭代器对象**
[[next()]] **手动迭代**对象

## 选择模型
如卷积层、池化层、批正则化层、LSTM层等），因此**深度神经网络往往需要“逐层”搭建，或者预先定义好可以实现特定功能的模块，再把这些模块组装起来**

[[nn.Module类型]]

## 设定损失函数、初始化参数、优化方法
模型设定的灵活性，**因此损失函数和优化器要能够保证反向传播能够在用户自行定义的模型结构上实现**。

定义损失函数


初始化参数
nn.init

定义优化方法
torch.optim


## 超参数
（当然可以使用sklearn这样的机器学习库中模型自带的损失函数和优化器）
。

## 最后用模型去拟合训练集数据
model.train()   # 训练状态
model.eval()   # 验证/测试状态

## 并在验证集/测试集上计算模型表现
个完整的图像分类的训练过程：
```python
def train(epoch):
    model.train()
    train_loss = 0
    for data, label in train_loader:
        data, label = data.cuda(), label.cuda()
        optimizer.zero_grad()
        output = model(data)
        loss = criterion(output, label)
        loss.backward()
        optimizer.step()
        train_loss += loss.item()*data.size(0)
    train_loss = train_loss/len(train_loader.dataset)
		print('Epoch: {} \tTraining Loss: {:.6f}'.format(epoch, train_loss))
```

一个完整图像分类的验证过程：
```python
def val(epoch):       
    model.eval()
    val_loss = 0
    with torch.no_grad():
        for data, label in val_loader:
            data, label = data.cuda(), label.cuda()
            output = model(data)
            preds = torch.argmax(output, 1)
            loss = criterion(output, label)
            val_loss += loss.item()*data.size(0)
            running_accu += torch.sum(preds == label.data)
    val_loss = val_loss/len(val_loader.dataset)
    print('Epoch: {} \tTraining Loss: {:.6f}'.format(epoch, val_loss))
```