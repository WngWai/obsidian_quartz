
https://bingqiangzhou.github.io/2020/08/26/DailySummary-NormalizationStandardizationRegularization.html

中心化（Centering）、归一化（Normalization）、标准化（Standardization）和正则化（Regularization）是数据预处理和模型正则化的不同技术，它们在机器学习和统计数据分析中有着广泛的应用。这些技术的目的和应用场景有所不同，下面是对它们的基本解释和区别：


概括：
- **中心化**仅涉及更改数据的中心位置，让平均值为0。


- **归一化**调整数据的尺度，使之落在特定的区间内，如[0, 1]。

	（1）使其不同尺度之间的特征具有**可比性**，同时不改变**原始数据的分布**。让模型不会**偏向**于某一个特征，如果x1的尺度为0至1，x2的尺度为0至10000，那么x2的变动将会产生更大的影响。
	（2）加括梯度下降的效率，提升模型的收敛速度。

	稀疏数据不能进行特征缩放，会导致出现较多的异常0值。
	数据不稳定，存在极端的最大最小值，不要用归一化。

- **标准化**调整数据分布，使之具有零均值和单位方差，有助于数据符合正态分布。

	（1）无从下手，可以直接使用标准化；

- **正则化**是一种减少模型过拟合的策略，通过在损失函数中添加正则项实现。


## 数据预处理
### **中心化（Centering）**

中心化是指将数据集的**每个特征的平均值移动到零点**，或者说是将数据集的中心移动到原点。这是通过从每个数据点减去其特征的平均值来完成的。中心化是**标准化的一个组成部分**，但它本身并不涉及缩放数据的大小。

### **归一化（Normalization）**
`数据比较平均，类似区间分布`
归一化通常指的是将数据**按比例缩放**，使之落入一个小的特定区间，例如[0, 1]。在某些情况下，归一化可能也指将数据缩放到[-1, 1]。归一化的目的是**改变原始数据的尺度，而不改变其分布的形状**，使得不同特征之间具有可比性，经常用于神经网络的输入数据处理。

### **标准化（Standardization）**
`要求数据符合对称分布`
标准化是将数据缩放使其具有零均值（μ=0）和单位方差（σ=1）。这通过对每个特征（列）**减去其平均值（均值）并除以标准差**来实现。标准化不受异常值的影响，经常用于支持向量机、逻辑回归和其他基于距离的算法中。

### 博克斯-考克斯变换（Box-Cox transformation）
`当偏度较高的（不对称、不均匀）,​​会改变原数据分布形状，因为引入了对数函数，λ！​​​​​​​`
>$$x_{box-cox}=\frac{x^{\lambda}-1}{\lambda}$$

## 改善模型训练效果
改善模型训练过程，提升模型的泛化性能
### **正则化（Regularization）**

正则化是机器学习中用来**防止过拟合的一种技术**。它通常通过在损失函数中**添加一个正则化项**来实现，这个正则化项惩罚模型的复杂度。常见的正则化技术包括L1正则化（也称为Lasso），它对**系数的绝对值**进行惩罚；L2正则化（也称为Ridge），它对**系数的平方**进行惩罚；还有弹性网（Elastic Net），它是L1和L2正则化的组合。




## 使用标准
### PCA
在主成分分析（PCA）降维中，数据预处理是一个重要的步骤，其中标准化是一个关键环节。以下是如何判断是否需要进行标准化操作，以及如何评价标准化数据对降维效果的标准的说明：

是否需要进行标准化：

1. **变量量纲和尺度**：如果数据的变量具有不同的量纲和尺度，例如一个变量的范围是0-100，而另一个变量的范围是0-1,000,000，那么就需要进行标准化。PCA受变量尺度的影响很大，不同尺度的变量会导致PCA主要识别那些尺度较大的变量，而忽略尺度较小的变量。

2. **分布形状**：如果变量的分布差异很大，例如一些变量是正态分布，而另一些是偏态分布或具有重尾特征，那么标准化可以帮助使数据更均匀地分布，从而使PCA更有效。

3. **数据类型**：对于定量数据，通常建议进行标准化。但对于定性数据（如性别、颜色等），可能不需要或不能进行标准化。

标准化的数据对降维效果的评价标准：
1. **方差解释率**：通过计算PCA每个主成分所解释的方差比例，可以评估降维的效果。理想情况下，**前几个主成分应该能够解释数据的大部分方差**。

2. **累积方差解释率**：通常希望选择的主**成分能够累积解释数据的大部分方差**（例如，超过70%或80%）。这可以通过**累积方差解释图**来评估。

3. **特征值和特征向量**：PCA中，特征值表示对应主成分的方差大小。较大的特征值意味着该主成分解释了更多的数据变异。特征向量则表示数据在这些主成分方向上的分布。

4. **可视化**：通过将数据投影到前两个或三个主成分上，可以进行可视化，这**有助于理解数据结构和评估降维效果**。

5. **模型性能**：如果降维是**为了后续的机器学习模型**，可以通过比较降维前后模型的性能（如准确率、召回率等）来评价降维的效果。

总之，标准化通常是有益的，特别是当数据变量之间存在显著的量纲和尺度差异时。降维效果的好坏可以通过多种统计和可视化方法来评价，重要的是要根据具体的应用场景和数据特性来选择合适的评价标准。

