tensor张量：具有任**意数量轴的n维数组**的通用方法。其实张量强调的是数学层面的概念，array数组强调计算机层面上的概念，两种在python中其实等同！其下都包含向量、矩阵、高纬度等概念。所以ndarry中的一些函数可以直接用于tensor中，名称都一样！

Tensor和numpy对象共享内存，所以他们之间的转换很快，而且几乎不会消耗什么资源。但这也意味着，如果其中一个变了，另外一个也会随之改变。需要注意的是，tensor()或者 tensor.clone() 总是会进行数据拷贝，新tensor和原来的数据**不再共享内存**。所以如果你想共享内存的话，建议使用torch.from.numpy() 或者 tensor.detach() 来新建一个tensor, 二者共享内存

### 生成张量
[[torch.tensor()]] 根据现有数据创建张量，为主要创建张量方式
[[t.clone()]] 不赋值地址，创建新的张量，并赋予新的地址
[[torch.arange()]] 按序数生成张量
[[torch.zeros()]] 初始元素为0的张量
[[torch.zeros_like()]]生成与张量相同类型、结构的全零张量
[[torch.ones()]] 初始元素为1的张量
[[torch.from_numpy()]]将numpy中的ndarray数组对象转变为向量

随机概率分布取样
[[torch.randn()]]标准正态分布随机取样形成张量
[[torch.normal()]]正态分布随机取样形成张量

生成新张量
[[t.detach()]] 从计算图中分离出来

### 属性
[[t.dtype]] 查看**张量数据类型**
[[t.dim()]]获得张量**维度**，几维
[[len(t)]]向量的长度、元素个数。张量的**第一个维度的大小**，也就是二维张量（矩阵）的行数
t.device 产看张量**在哪个设备上**，是cpu，还是GPU
t.item()适用于单个元素的张量**提值**，将一个标量张量转换为一个Python数值


t.shape 张量**形状**元组，是张量的属性！
[[t.size()]] 返回张量的**形状**，是一个方法，结果跟t.shape一样
[[t.numel()]] 张量**元素总数**

[[t.grad_fn]]**跟踪创建张量的操作**的属性


### 索引：下标也是从0是头，-1是尾
t[-1, :]，也是t[-1]  取倒数第一行的数据，跟pandas中df数据的标签索引先列后行相区分！
t[1:3, :]，也是t[1:3] 取第2行和第3行数据，**左闭右开**，普遍具有类似特征
t[\:\:1,\:\:2]，从开始到结束，每隔1或2个元素选择一个
### 运算
标准算术运算（四则运算）

**逐元素乘法** 结果是张量，[[torch.mul()]]（ 等价于`@` 或 `*` ）对应元素相乘，跟点积不同；加、减对应元素加减

[[torch.cross()]]向量的**向量积**（叉积、叉乘），结果是垂直于两个向量的新向量

线性代数运算
[[torch.dot()]]两个**一维张量（向量）** 的**点积（内积）**,结果是**标量**
[[torch.mv()]] **矩阵和向量**的乘法操作
[[torch.mm()]] **矩阵和矩阵**的乘法操作，也称为矩阵的乘法
[[torch.matmul()]] **矩阵与矩阵、矩阵与向量、向量与矩阵**的乘法
[[torch.norm()]]计算**范数**，向量或矩阵长度

t.pow()求次方 
[[t.sum()]]对元素进行求和，得到标量
[[t.mean()]] 等价于t.sum()/t.numel()
t.average()
[[t.add()]]元素对应进行相加
[[t.cumsum()]] 累加求和

### 统计运算
[[t.argmax()]]返回张量中**最大元素的索引**


### 常规操作
#### 增
合并
[[torch.cat()]] 在给定维度上进行张量拼接，形成一个新的张量

#### 删


#### 改
属性：
[[t.type()]]改变张量数据类型
[[t.reshape()]]改变张量形状，对元素重排，-1处的维度会被框架自动计算出。可以处理**连续和非连续**张量的重新塑形
[[t.view()]]改变张量形状，对元素重排，张量必须**连续**，性能会更优
[[t.squeeze()]]**从张量中移除尺寸为1的维度**
[[t.unsqueeze()]]**从张量中插入尺寸为1的维度**

元素：
[[t.T]] 只使用于二维张量的装置转置
[[t.transpose()]] 维度转换



#### 查
切片

