1，数据为16位浮点型更适应GPU
要比32位浮点型更适用GPU运算，速度大概快两倍。

2，矩阵乘法比索引要更高效
```python
 mask = (torch.rand(X.shape) > dropout).float()
 # 矩阵乘法
 mask * X / (1.0 - dropout)

 # 元素索引
 X[mask]
```

